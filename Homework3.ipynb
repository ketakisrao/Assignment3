{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv('output.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100000, 13)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_cat = ['race', 'sex', 'relationship_status']\n",
    "features_num = ['age', 'education']\n",
    "\n",
    "X_cat = df[features_cat]\n",
    "X_num = df[features_num]\n",
    "enc = preprocessing.OneHotEncoder()\n",
    "enc.fit(X_cat)\n",
    "one_hot = enc.transform(X_cat)\n",
    "X_cat_proc = pandas.DataFrame(one_hot.toarray(), columns=enc.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled = preprocessing.scale(X_num, with_mean=True, with_std=True)\n",
    "X_num_proc = pandas.DataFrame(scaled, columns=features_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pandas.concat([X_num_proc, X_cat_proc], axis=1, sort=False)\n",
    "X = X.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['New_group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_TEMP, y_train, y_TEMP = train_test_split(X, y, test_size=0.30) # split out into training 70% of our data\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_TEMP, y_TEMP, test_size=0.50) # split out into validation 15% of our data and test 15% of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ketakisrao/anaconda3/lib/python3.7/site-packages/sklearn/discriminant_analysis.py:388: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n",
      "/Users/ketakisrao/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix:\n",
      " [[  18   90    0    0    0   92    0  114    0    0    0    1    0    0\n",
      "     0]\n",
      " [   7 1244    0    0    0   57    0 2082    0    0    0    1    0    0\n",
      "     0]\n",
      " [  14   41    0    0    0   65    0  800    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2  212    0    0    0   38    0  582    0    0    0    1    0    0\n",
      "     0]\n",
      " [   0  152    0    0    0   22    0  852    0    0    0    0    0    0\n",
      "     0]\n",
      " [  12  203    0    0    0  179    0  147    0    0    0    0    0    0\n",
      "     0]\n",
      " [   1   26    0    0    0    5    0  170    0    0    0    0    0    0\n",
      "     0]\n",
      " [  12  816    0    0    0   77    0 3866    0    2    0    3    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "     0]\n",
      " [   1   60    0    0    0    8    0  227    0    0    0    0    0    0\n",
      "     0]\n",
      " [   5  279    0    0    0   19    0 1237    0    0    0    1    0    0\n",
      "     0]\n",
      " [   0   10    0    0    0    4    0   15    0    0    0    0    0    0\n",
      "     0]\n",
      " [   0    0    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "     0]\n",
      " [   4  241    0    0    0   28    0  675    0    0    0    1    0    1\n",
      "     0]\n",
      " [   4   41    0    0    0   16    0  115    0    0    0    0    0    0\n",
      "     0]]\n",
      "\n",
      "Report:\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "                      Accident       0.23      0.06      0.09       315\n",
      "                        Cancer       0.36      0.37      0.37      3391\n",
      "          Congenital Anomalies       0.00      0.00      0.00       920\n",
      "                      Diabetes       0.00      0.00      0.00       835\n",
      "Diseases of the nervous system       0.00      0.00      0.00      1026\n",
      "                      Drug Use       0.29      0.33      0.31       541\n",
      "                          Fall       0.00      0.00      0.00       202\n",
      "                 Heart Disease       0.36      0.81      0.49      4776\n",
      "                 Heat Exposure       0.00      0.00      0.00         1\n",
      "                     Infection       0.00      0.00      0.00       296\n",
      "              Issues Breathing       0.00      0.00      0.00      1541\n",
      "            Medical Care Error       0.00      0.00      0.00        29\n",
      "            Military Situation       0.00      0.00      0.00         1\n",
      "                 Organ Failure       1.00      0.00      0.00       950\n",
      "                         Other       0.00      0.00      0.00       176\n",
      "\n",
      "                      accuracy                           0.35     15000\n",
      "                     macro avg       0.15      0.10      0.08     15000\n",
      "                  weighted avg       0.27      0.35      0.25     15000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# helper method to print basic model metrics\n",
    "def metrics(y_true, y_pred):\n",
    "    print('Confusion matrix:\\n', confusion_matrix(y_true, y_pred))\n",
    "    # target_names = ['denied', 'approved']\n",
    "    print('\\nReport:\\n', classification_report(y_true, y_pred))\n",
    "\n",
    "    \n",
    "logistic_regression = LogisticRegression(solver='lbfgs', multi_class='ovr', max_iter=250)\n",
    "decision_tree_classifier = DecisionTreeClassifier()\n",
    "naive_bayes = GaussianNB()\n",
    "knn = KNeighborsClassifier()\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "random_forest = RandomForestClassifier(bootstrap=True);\n",
    "\n",
    "model = lda.fit(X_train, y_train) # first fit (train) the model\n",
    "y_pred = model.predict(X_validation) # next get the model's predictions for a sample in the validation set\n",
    "metrics(y_validation, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "predict_data_cat = [['Hawaiian', 'F', 'Married']]\n",
    "#['Black', 'M', 'Single'], ['White', 'M', 'Widowed'], ['Hawaiian', 'F', 'Married']\n",
    "#[20, 6], [72, 3], [36, 5]\n",
    "predict_data_num = [[36, 5]]\n",
    "\n",
    "Y = enc.transform(predict_data_cat)\n",
    "Y = pandas.DataFrame(Y.toarray(), columns=enc.get_feature_names())\n",
    "\n",
    "s = preprocessing.scale(predict_data_num)\n",
    "s = pandas.DataFrame(s, columns=features_num)\n",
    "Y = pandas.concat([s, Y], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Medical Care Error']\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(Y)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deaths_model', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('deaths_model', 'rb') as f:\n",
    "    model2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Heart Disease', 'Heart Disease', 'Medical Care Error'],\n",
       "      dtype='<U33')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(X.columns)\n",
    "columns = columns[2:]\n",
    "with open('columns', 'wb') as file:\n",
    "    pickle.dump(columns, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0_Black</th>\n",
       "      <th>x0_Chinese</th>\n",
       "      <th>x0_Filipino</th>\n",
       "      <th>x0_Guamanian</th>\n",
       "      <th>x0_Hawaiian</th>\n",
       "      <th>x0_Indian</th>\n",
       "      <th>x0_Japanese</th>\n",
       "      <th>x0_Korean</th>\n",
       "      <th>x0_Native American</th>\n",
       "      <th>x0_Samoan</th>\n",
       "      <th>x0_Vietnamese</th>\n",
       "      <th>x0_White</th>\n",
       "      <th>x0_other Asian or Pacific Islander</th>\n",
       "      <th>x1_F</th>\n",
       "      <th>x1_M</th>\n",
       "      <th>x2_Divorced</th>\n",
       "      <th>x2_Married</th>\n",
       "      <th>x2_Single</th>\n",
       "      <th>x2_Unkown</th>\n",
       "      <th>x2_Widowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x0_Black  x0_Chinese  x0_Filipino  x0_Guamanian  x0_Hawaiian  x0_Indian  \\\n",
       "0       1.0           0            0             0          0.0          0   \n",
       "1       0.0           0            0             0          0.0          0   \n",
       "2       0.0           0            0             0          1.0          0   \n",
       "\n",
       "   x0_Japanese  x0_Korean  x0_Native American  x0_Samoan  x0_Vietnamese  \\\n",
       "0            0          0                   0          0              0   \n",
       "1            0          0                   0          0              0   \n",
       "2            0          0                   0          0              0   \n",
       "\n",
       "   x0_White  x0_other Asian or Pacific Islander  x1_F  x1_M  x2_Divorced  \\\n",
       "0       0.0                                   0   0.0   1.0            0   \n",
       "1       1.0                                   0   0.0   1.0            0   \n",
       "2       0.0                                   0   1.0   0.0            0   \n",
       "\n",
       "   x2_Married  x2_Single  x2_Unkown  x2_Widowed  \n",
       "0         0.0        1.0          0         0.0  \n",
       "1         0.0        0.0          0         1.0  \n",
       "2         1.0        0.0          0         0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query = pandas.get_dummies(pandas.DataFrame(predict_data_cat))\n",
    "enc1 = preprocessing.OneHotEncoder()\n",
    "enc1.fit(predict_data_cat)\n",
    "one_hot1 = enc1.transform(predict_data_cat)\n",
    "X_cat_processed = pandas.DataFrame(one_hot1.toarray(), columns=enc1.get_feature_names())\n",
    "# X_cat_processed.head()\n",
    "query = X_cat_processed.reindex(columns=columns, fill_value=0)\n",
    "query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>education</th>\n",
       "      <th>x0_Black</th>\n",
       "      <th>x0_Chinese</th>\n",
       "      <th>x0_Filipino</th>\n",
       "      <th>x0_Guamanian</th>\n",
       "      <th>x0_Hawaiian</th>\n",
       "      <th>x0_Indian</th>\n",
       "      <th>x0_Japanese</th>\n",
       "      <th>x0_Korean</th>\n",
       "      <th>...</th>\n",
       "      <th>x0_Vietnamese</th>\n",
       "      <th>x0_White</th>\n",
       "      <th>x0_other Asian or Pacific Islander</th>\n",
       "      <th>x1_F</th>\n",
       "      <th>x1_M</th>\n",
       "      <th>x2_Divorced</th>\n",
       "      <th>x2_Married</th>\n",
       "      <th>x2_Single</th>\n",
       "      <th>x2_Unkown</th>\n",
       "      <th>x2_Widowed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.042337</td>\n",
       "      <td>1.069045</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.348907</td>\n",
       "      <td>-1.336306</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.306570</td>\n",
       "      <td>0.267261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        age  education  x0_Black  x0_Chinese  x0_Filipino  x0_Guamanian  \\\n",
       "0 -1.042337   1.069045       1.0           0            0             0   \n",
       "1  1.348907  -1.336306       0.0           0            0             0   \n",
       "2 -0.306570   0.267261       0.0           0            0             0   \n",
       "\n",
       "   x0_Hawaiian  x0_Indian  x0_Japanese  x0_Korean  ...  x0_Vietnamese  \\\n",
       "0          0.0          0            0          0  ...              0   \n",
       "1          0.0          0            0          0  ...              0   \n",
       "2          1.0          0            0          0  ...              0   \n",
       "\n",
       "   x0_White  x0_other Asian or Pacific Islander  x1_F  x1_M  x2_Divorced  \\\n",
       "0       0.0                                   0   0.0   1.0            0   \n",
       "1       1.0                                   0   0.0   1.0            0   \n",
       "2       0.0                                   0   1.0   0.0            0   \n",
       "\n",
       "   x2_Married  x2_Single  x2_Unkown  x2_Widowed  \n",
       "0         0.0        1.0          0         0.0  \n",
       "1         0.0        0.0          0         1.0  \n",
       "2         1.0        0.0          0         0.0  \n",
       "\n",
       "[3 rows x 22 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = preprocessing.scale(predict_data_num)\n",
    "s = pandas.DataFrame(s, columns=features_num)\n",
    "query = pandas.concat([s, query], axis=1, sort=False)\n",
    "query.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Heart Disease', 'Heart Disease', 'Medical Care Error'],\n",
       "      dtype='<U33')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
